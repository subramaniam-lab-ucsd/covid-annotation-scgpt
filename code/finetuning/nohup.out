/home/s5srinivasan/py39env/lib64/python3.9/site-packages/scgpt/model/model.py:21: UserWarning: flash_attn is not installed
  warnings.warn("flash_attn is not installed")
/home/s5srinivasan/py39env/lib64/python3.9/site-packages/scgpt/model/multiomic_model.py:19: UserWarning: flash_attn is not installed
  warnings.warn("flash_attn is not installed")
/home/s5srinivasan/py39env/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: srks (srks-uc-san-diego). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.7
wandb: Run data is saved locally in /home/s5srinivasan/covid-annotation-scgpt/code/finetuning/wandb/run-20250306_200750-zy7pstmg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-eon-119
wandb: ‚≠êÔ∏è View project at https://wandb.ai/srks-uc-san-diego/scGPT-covid-annotation
wandb: üöÄ View run at https://wandb.ai/srks-uc-san-diego/scGPT-covid-annotation/runs/zy7pstmg
{'seed': 0, 'dataset_name': 'covid', 'do_train': True, 'load_model': '/home/s5srinivasan/covid-annotation-scgpt/save/scgpt-human', 'mask_ratio': 0.0, 'epochs': 10, 'n_bins': 51, 'MVC': False, 'ecs_thres': 0.0, 'dab_weight': 0.0, 'lr': 5e-05, 'batch_size': 24, 'layer_size': 128, 'nlayers': 4, 'nhead': 4, 'dropout': 0.3, 'weight_decay': 0.01, 'schedule_ratio': 0.9, 'save_eval_interval': 5, 'fast_transformer': True, 'pre_norm': False, 'amp': True, 'include_zero_gene': False, 'freeze': False, 'DSBN': False}
save to /home/s5srinivasan/covid-annotation-scgpt/save/dev_covid-Mar06-20-07
/home/s5srinivasan/covid-annotation-scgpt/save/scgpt-human
scGPT - INFO - match 23325/33751 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/s5srinivasan/covid-annotation-scgpt/save/scgpt-human/best_model.pt, the model args will override the config /home/s5srinivasan/covid-annotation-scgpt/save/scgpt-human/args.json.
scGPT - INFO - Normalizing total counts ...
scGPT - INFO - Binning data ...
scGPT - INFO - Normalizing total counts ...
scGPT - INFO - Binning data ...
scGPT - INFO - train set number of samples: 170999, 
	 feature length: 3001
scGPT - INFO - valid set number of samples: 19000, 
	 feature length: 3001
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params decoder.fc.0.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params decoder.fc.0.bias with shape torch.Size([512])
scGPT - INFO - Loading params decoder.fc.2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params decoder.fc.2.bias with shape torch.Size([512])
scGPT - INFO - Loading params decoder.fc.4.weight with shape torch.Size([1, 512])
scGPT - INFO - Loading params decoder.fc.4.bias with shape torch.Size([1])
--------------------
name: encoder.embedding.weight
--------------------
name: encoder.enc_norm.weight
--------------------
name: encoder.enc_norm.bias
--------------------
name: value_encoder.linear1.weight
--------------------
name: value_encoder.linear1.bias
--------------------
name: value_encoder.linear2.weight
--------------------
name: value_encoder.linear2.bias
--------------------
name: value_encoder.norm.weight
--------------------
name: value_encoder.norm.bias
--------------------
name: transformer_encoder.layers.0.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.0.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.0.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.0.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.0.linear1.weight
--------------------
name: transformer_encoder.layers.0.linear1.bias
--------------------
name: transformer_encoder.layers.0.linear2.weight
--------------------
name: transformer_encoder.layers.0.linear2.bias
--------------------
name: transformer_encoder.layers.0.norm1.weight
--------------------
name: transformer_encoder.layers.0.norm1.bias
--------------------
name: transformer_encoder.layers.0.norm2.weight
--------------------
name: transformer_encoder.layers.0.norm2.bias
--------------------
name: transformer_encoder.layers.1.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.1.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.1.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.1.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.1.linear1.weight
--------------------
name: transformer_encoder.layers.1.linear1.bias
--------------------
name: transformer_encoder.layers.1.linear2.weight
--------------------
name: transformer_encoder.layers.1.linear2.bias
--------------------
name: transformer_encoder.layers.1.norm1.weight
--------------------
name: transformer_encoder.layers.1.norm1.bias
--------------------
name: transformer_encoder.layers.1.norm2.weight
--------------------
name: transformer_encoder.layers.1.norm2.bias
--------------------
name: transformer_encoder.layers.2.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.2.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.2.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.2.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.2.linear1.weight
--------------------
name: transformer_encoder.layers.2.linear1.bias
--------------------
name: transformer_encoder.layers.2.linear2.weight
--------------------
name: transformer_encoder.layers.2.linear2.bias
--------------------
name: transformer_encoder.layers.2.norm1.weight
--------------------
name: transformer_encoder.layers.2.norm1.bias
--------------------
name: transformer_encoder.layers.2.norm2.weight
--------------------
name: transformer_encoder.layers.2.norm2.bias
--------------------
name: transformer_encoder.layers.3.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.3.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.3.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.3.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.3.linear1.weight
--------------------
name: transformer_encoder.layers.3.linear1.bias
--------------------
name: transformer_encoder.layers.3.linear2.weight
--------------------
name: transformer_encoder.layers.3.linear2.bias
--------------------
name: transformer_encoder.layers.3.norm1.weight
--------------------
name: transformer_encoder.layers.3.norm1.bias
--------------------
name: transformer_encoder.layers.3.norm2.weight
--------------------
name: transformer_encoder.layers.3.norm2.bias
--------------------
name: transformer_encoder.layers.4.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.4.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.4.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.4.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.4.linear1.weight
--------------------
name: transformer_encoder.layers.4.linear1.bias
--------------------
name: transformer_encoder.layers.4.linear2.weight
--------------------
name: transformer_encoder.layers.4.linear2.bias
--------------------
name: transformer_encoder.layers.4.norm1.weight
--------------------
name: transformer_encoder.layers.4.norm1.bias
--------------------
name: transformer_encoder.layers.4.norm2.weight
--------------------
name: transformer_encoder.layers.4.norm2.bias
--------------------
name: transformer_encoder.layers.5.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.5.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.5.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.5.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.5.linear1.weight
--------------------
name: transformer_encoder.layers.5.linear1.bias
--------------------
name: transformer_encoder.layers.5.linear2.weight
--------------------
name: transformer_encoder.layers.5.linear2.bias
--------------------
name: transformer_encoder.layers.5.norm1.weight
--------------------
name: transformer_encoder.layers.5.norm1.bias
--------------------
name: transformer_encoder.layers.5.norm2.weight
--------------------
name: transformer_encoder.layers.5.norm2.bias
--------------------
name: transformer_encoder.layers.6.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.6.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.6.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.6.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.6.linear1.weight
--------------------
name: transformer_encoder.layers.6.linear1.bias
--------------------
name: transformer_encoder.layers.6.linear2.weight
--------------------
name: transformer_encoder.layers.6.linear2.bias
--------------------
name: transformer_encoder.layers.6.norm1.weight
--------------------
name: transformer_encoder.layers.6.norm1.bias
--------------------
name: transformer_encoder.layers.6.norm2.weight
--------------------
name: transformer_encoder.layers.6.norm2.bias
--------------------
name: transformer_encoder.layers.7.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.7.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.7.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.7.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.7.linear1.weight
--------------------
name: transformer_encoder.layers.7.linear1.bias
--------------------
name: transformer_encoder.layers.7.linear2.weight
--------------------
name: transformer_encoder.layers.7.linear2.bias
--------------------
name: transformer_encoder.layers.7.norm1.weight
--------------------
name: transformer_encoder.layers.7.norm1.bias
--------------------
name: transformer_encoder.layers.7.norm2.weight
--------------------
name: transformer_encoder.layers.7.norm2.bias
--------------------
name: transformer_encoder.layers.8.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.8.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.8.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.8.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.8.linear1.weight
--------------------
name: transformer_encoder.layers.8.linear1.bias
--------------------
name: transformer_encoder.layers.8.linear2.weight
--------------------
name: transformer_encoder.layers.8.linear2.bias
--------------------
name: transformer_encoder.layers.8.norm1.weight
--------------------
name: transformer_encoder.layers.8.norm1.bias
--------------------
name: transformer_encoder.layers.8.norm2.weight
--------------------
name: transformer_encoder.layers.8.norm2.bias
--------------------
name: transformer_encoder.layers.9.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.9.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.9.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.9.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.9.linear1.weight
--------------------
name: transformer_encoder.layers.9.linear1.bias
--------------------
name: transformer_encoder.layers.9.linear2.weight
--------------------
name: transformer_encoder.layers.9.linear2.bias
--------------------
name: transformer_encoder.layers.9.norm1.weight
--------------------
name: transformer_encoder.layers.9.norm1.bias
--------------------
name: transformer_encoder.layers.9.norm2.weight
--------------------
name: transformer_encoder.layers.9.norm2.bias
--------------------
name: transformer_encoder.layers.10.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.10.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.10.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.10.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.10.linear1.weight
--------------------
name: transformer_encoder.layers.10.linear1.bias
--------------------
name: transformer_encoder.layers.10.linear2.weight
--------------------
name: transformer_encoder.layers.10.linear2.bias
--------------------
name: transformer_encoder.layers.10.norm1.weight
--------------------
name: transformer_encoder.layers.10.norm1.bias
--------------------
name: transformer_encoder.layers.10.norm2.weight
--------------------
name: transformer_encoder.layers.10.norm2.bias
--------------------
name: transformer_encoder.layers.11.self_attn.in_proj_weight
--------------------
name: transformer_encoder.layers.11.self_attn.in_proj_bias
--------------------
name: transformer_encoder.layers.11.self_attn.out_proj.weight
--------------------
name: transformer_encoder.layers.11.self_attn.out_proj.bias
--------------------
name: transformer_encoder.layers.11.linear1.weight
--------------------
name: transformer_encoder.layers.11.linear1.bias
--------------------
name: transformer_encoder.layers.11.linear2.weight
--------------------
name: transformer_encoder.layers.11.linear2.bias
--------------------
name: transformer_encoder.layers.11.norm1.weight
--------------------
name: transformer_encoder.layers.11.norm1.bias
--------------------
name: transformer_encoder.layers.11.norm2.weight
--------------------
name: transformer_encoder.layers.11.norm2.bias
--------------------
name: decoder.fc.0.weight
--------------------
name: decoder.fc.0.bias
--------------------
name: decoder.fc.2.weight
--------------------
name: decoder.fc.2.bias
--------------------
name: decoder.fc.4.weight
--------------------
name: decoder.fc.4.bias
--------------------
name: cls_decoder._decoder.0.weight
--------------------
name: cls_decoder._decoder.0.bias
--------------------
name: cls_decoder._decoder.2.weight
--------------------
name: cls_decoder._decoder.2.bias
--------------------
name: cls_decoder._decoder.3.weight
--------------------
name: cls_decoder._decoder.3.bias
--------------------
name: cls_decoder._decoder.5.weight
--------------------
name: cls_decoder._decoder.5.bias
--------------------
name: cls_decoder.out_layer.weight
--------------------
name: cls_decoder.out_layer.bias
scGPT - INFO - Total Pre freeze Params 51353131
scGPT - INFO - Total Post freeze Params 51353131
scGPT - INFO - Using 3 GPUs
Number of available GPUs: 3
random masking at epoch   1, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch   1 | 100/7125 batches | lr 0.0001 | ms/batch 560.42 | loss  2.89 | cls  2.89 | err  0.84 | 
scGPT - INFO - | epoch   1 | 200/7125 batches | lr 0.0001 | ms/batch 520.94 | loss  2.77 | cls  2.77 | err  0.82 | 
scGPT - INFO - | epoch   1 | 300/7125 batches | lr 0.0001 | ms/batch 524.49 | loss  2.21 | cls  2.21 | err  0.62 | 
scGPT - INFO - | epoch   1 | 400/7125 batches | lr 0.0001 | ms/batch 527.12 | loss  1.75 | cls  1.75 | err  0.49 | 
scGPT - INFO - | epoch   1 | 500/7125 batches | lr 0.0001 | ms/batch 526.99 | loss  1.52 | cls  1.52 | err  0.43 | 
scGPT - INFO - | epoch   1 | 600/7125 batches | lr 0.0001 | ms/batch 527.38 | loss  1.43 | cls  1.43 | err  0.42 | 
scGPT - INFO - | epoch   1 | 700/7125 batches | lr 0.0001 | ms/batch 529.22 | loss  1.33 | cls  1.33 | err  0.40 | 
scGPT - INFO - | epoch   1 | 800/7125 batches | lr 0.0001 | ms/batch 528.01 | loss  1.21 | cls  1.21 | err  0.36 | 
scGPT - INFO - | epoch   1 | 900/7125 batches | lr 0.0001 | ms/batch 528.00 | loss  1.09 | cls  1.09 | err  0.30 | 
scGPT - INFO - | epoch   1 | 1000/7125 batches | lr 0.0001 | ms/batch 530.53 | loss  1.03 | cls  1.03 | err  0.29 | 
scGPT - INFO - | epoch   1 | 1100/7125 batches | lr 0.0001 | ms/batch 527.96 | loss  0.95 | cls  0.95 | err  0.26 | 
scGPT - INFO - | epoch   1 | 1200/7125 batches | lr 0.0001 | ms/batch 529.12 | loss  0.92 | cls  0.92 | err  0.26 | 
scGPT - INFO - | epoch   1 | 1300/7125 batches | lr 0.0001 | ms/batch 529.35 | loss  0.93 | cls  0.93 | err  0.26 | 
scGPT - INFO - | epoch   1 | 1400/7125 batches | lr 0.0001 | ms/batch 529.20 | loss  0.94 | cls  0.94 | err  0.27 | 
scGPT - INFO - | epoch   1 | 1500/7125 batches | lr 0.0001 | ms/batch 529.37 | loss  0.88 | cls  0.88 | err  0.25 | 
scGPT - INFO - | epoch   1 | 1600/7125 batches | lr 0.0001 | ms/batch 528.78 | loss  0.85 | cls  0.85 | err  0.25 | 
scGPT - INFO - | epoch   1 | 1700/7125 batches | lr 0.0001 | ms/batch 529.08 | loss  0.82 | cls  0.82 | err  0.25 | 
scGPT - INFO - | epoch   1 | 1800/7125 batches | lr 0.0001 | ms/batch 529.86 | loss  0.83 | cls  0.83 | err  0.24 | 
scGPT - INFO - | epoch   1 | 1900/7125 batches | lr 0.0001 | ms/batch 528.70 | loss  0.79 | cls  0.79 | err  0.24 | 
scGPT - INFO - | epoch   1 | 2000/7125 batches | lr 0.0001 | ms/batch 530.27 | loss  0.79 | cls  0.79 | err  0.23 | 
scGPT - INFO - | epoch   1 | 2100/7125 batches | lr 0.0001 | ms/batch 530.29 | loss  0.78 | cls  0.78 | err  0.24 | 
scGPT - INFO - | epoch   1 | 2200/7125 batches | lr 0.0001 | ms/batch 527.82 | loss  0.74 | cls  0.74 | err  0.22 | 
scGPT - INFO - | epoch   1 | 2300/7125 batches | lr 0.0001 | ms/batch 530.34 | loss  0.74 | cls  0.74 | err  0.22 | 
scGPT - INFO - | epoch   1 | 2400/7125 batches | lr 0.0001 | ms/batch 527.71 | loss  0.74 | cls  0.74 | err  0.22 | 
scGPT - INFO - | epoch   1 | 2500/7125 batches | lr 0.0001 | ms/batch 527.54 | loss  0.69 | cls  0.69 | err  0.22 | 
scGPT - INFO - | epoch   1 | 2600/7125 batches | lr 0.0001 | ms/batch 527.56 | loss  0.66 | cls  0.66 | err  0.19 | 
scGPT - INFO - | epoch   1 | 2700/7125 batches | lr 0.0001 | ms/batch 528.91 | loss  0.71 | cls  0.71 | err  0.23 | 
scGPT - INFO - | epoch   1 | 2800/7125 batches | lr 0.0001 | ms/batch 528.50 | loss  0.64 | cls  0.64 | err  0.20 | 
scGPT - INFO - | epoch   1 | 2900/7125 batches | lr 0.0001 | ms/batch 527.61 | loss  0.60 | cls  0.60 | err  0.19 | 
scGPT - INFO - | epoch   1 | 3000/7125 batches | lr 0.0001 | ms/batch 529.83 | loss  0.59 | cls  0.59 | err  0.19 | 
scGPT - INFO - | epoch   1 | 3100/7125 batches | lr 0.0001 | ms/batch 528.82 | loss  0.64 | cls  0.64 | err  0.20 | 
scGPT - INFO - | epoch   1 | 3200/7125 batches | lr 0.0001 | ms/batch 528.92 | loss  0.58 | cls  0.58 | err  0.19 | 
scGPT - INFO - | epoch   1 | 3300/7125 batches | lr 0.0001 | ms/batch 529.08 | loss  0.61 | cls  0.61 | err  0.19 | 
scGPT - INFO - | epoch   1 | 3400/7125 batches | lr 0.0001 | ms/batch 527.72 | loss  0.58 | cls  0.58 | err  0.19 | 
scGPT - INFO - | epoch   1 | 3500/7125 batches | lr 0.0001 | ms/batch 527.85 | loss  0.60 | cls  0.60 | err  0.19 | 
scGPT - INFO - | epoch   1 | 3600/7125 batches | lr 0.0001 | ms/batch 527.85 | loss  0.58 | cls  0.58 | err  0.18 | 
scGPT - INFO - | epoch   1 | 3700/7125 batches | lr 0.0001 | ms/batch 528.78 | loss  0.58 | cls  0.58 | err  0.18 | 
scGPT - INFO - | epoch   1 | 3800/7125 batches | lr 0.0001 | ms/batch 527.47 | loss  0.60 | cls  0.60 | err  0.19 | 
scGPT - INFO - | epoch   1 | 3900/7125 batches | lr 0.0001 | ms/batch 527.47 | loss  0.56 | cls  0.56 | err  0.18 | 
scGPT - INFO - | epoch   1 | 4000/7125 batches | lr 0.0001 | ms/batch 529.59 | loss  0.59 | cls  0.59 | err  0.19 | 
scGPT - INFO - | epoch   1 | 4100/7125 batches | lr 0.0001 | ms/batch 528.81 | loss  0.58 | cls  0.58 | err  0.18 | 
scGPT - INFO - | epoch   1 | 4200/7125 batches | lr 0.0001 | ms/batch 528.70 | loss  0.56 | cls  0.56 | err  0.18 | 
scGPT - INFO - | epoch   1 | 4300/7125 batches | lr 0.0001 | ms/batch 528.30 | loss  0.53 | cls  0.53 | err  0.17 | 
scGPT - INFO - | epoch   1 | 4400/7125 batches | lr 0.0001 | ms/batch 527.58 | loss  0.58 | cls  0.58 | err  0.18 | 
scGPT - INFO - | epoch   1 | 4500/7125 batches | lr 0.0001 | ms/batch 527.54 | loss  0.56 | cls  0.56 | err  0.18 | 
scGPT - INFO - | epoch   1 | 4600/7125 batches | lr 0.0001 | ms/batch 529.59 | loss  0.51 | cls  0.51 | err  0.16 | 
scGPT - INFO - | epoch   1 | 4700/7125 batches | lr 0.0001 | ms/batch 527.46 | loss  0.57 | cls  0.57 | err  0.18 | 
scGPT - INFO - | epoch   1 | 4800/7125 batches | lr 0.0001 | ms/batch 527.50 | loss  0.51 | cls  0.51 | err  0.18 | 
scGPT - INFO - | epoch   1 | 4900/7125 batches | lr 0.0001 | ms/batch 528.55 | loss  0.54 | cls  0.54 | err  0.17 | 
scGPT - INFO - | epoch   1 | 5000/7125 batches | lr 0.0001 | ms/batch 528.17 | loss  0.50 | cls  0.50 | err  0.16 | 
scGPT - INFO - | epoch   1 | 5100/7125 batches | lr 0.0001 | ms/batch 528.68 | loss  0.50 | cls  0.50 | err  0.17 | 
scGPT - INFO - | epoch   1 | 5200/7125 batches | lr 0.0001 | ms/batch 528.67 | loss  0.52 | cls  0.52 | err  0.18 | 
scGPT - INFO - | epoch   1 | 5300/7125 batches | lr 0.0001 | ms/batch 528.76 | loss  0.53 | cls  0.53 | err  0.17 | 
scGPT - INFO - | epoch   1 | 5400/7125 batches | lr 0.0001 | ms/batch 527.36 | loss  0.50 | cls  0.50 | err  0.17 | 
scGPT - INFO - | epoch   1 | 5500/7125 batches | lr 0.0001 | ms/batch 527.48 | loss  0.51 | cls  0.51 | err  0.17 | 
scGPT - INFO - | epoch   1 | 5600/7125 batches | lr 0.0001 | ms/batch 528.56 | loss  0.52 | cls  0.52 | err  0.18 | 
scGPT - INFO - | epoch   1 | 5700/7125 batches | lr 0.0001 | ms/batch 527.52 | loss  0.52 | cls  0.52 | err  0.18 | 
scGPT - INFO - | epoch   1 | 5800/7125 batches | lr 0.0001 | ms/batch 527.46 | loss  0.52 | cls  0.52 | err  0.17 | 
scGPT - INFO - | epoch   1 | 5900/7125 batches | lr 0.0001 | ms/batch 528.65 | loss  0.50 | cls  0.50 | err  0.16 | 
scGPT - INFO - | epoch   1 | 6000/7125 batches | lr 0.0001 | ms/batch 528.30 | loss  0.50 | cls  0.50 | err  0.16 | 
scGPT - INFO - | epoch   1 | 6100/7125 batches | lr 0.0001 | ms/batch 528.71 | loss  0.50 | cls  0.50 | err  0.16 | 
scGPT - INFO - | epoch   1 | 6200/7125 batches | lr 0.0001 | ms/batch 528.68 | loss  0.49 | cls  0.49 | err  0.16 | 
scGPT - INFO - | epoch   1 | 6300/7125 batches | lr 0.0001 | ms/batch 528.68 | loss  0.53 | cls  0.53 | err  0.18 | 
scGPT - INFO - | epoch   1 | 6400/7125 batches | lr 0.0001 | ms/batch 527.46 | loss  0.49 | cls  0.49 | err  0.16 | 
scGPT - INFO - | epoch   1 | 6500/7125 batches | lr 0.0001 | ms/batch 527.58 | loss  0.50 | cls  0.50 | err  0.16 | 
scGPT - INFO - | epoch   1 | 6600/7125 batches | lr 0.0001 | ms/batch 528.76 | loss  0.51 | cls  0.51 | err  0.17 | 
scGPT - INFO - | epoch   1 | 6700/7125 batches | lr 0.0001 | ms/batch 527.53 | loss  0.47 | cls  0.47 | err  0.16 | 
scGPT - INFO - | epoch   1 | 6800/7125 batches | lr 0.0001 | ms/batch 527.54 | loss  0.55 | cls  0.55 | err  0.18 | 
scGPT - INFO - | epoch   1 | 6900/7125 batches | lr 0.0001 | ms/batch 528.76 | loss  0.46 | cls  0.46 | err  0.16 | 
scGPT - INFO - | epoch   1 | 7000/7125 batches | lr 0.0001 | ms/batch 528.33 | loss  0.47 | cls  0.47 | err  0.16 | 
scGPT - INFO - | epoch   1 | 7100/7125 batches | lr 0.0001 | ms/batch 528.72 | loss  0.49 | cls  0.49 | err  0.16 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 3937.64s | valid loss/mse 0.5127 | err 0.1720
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.5127
random masking at epoch   2, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch   2 | 100/7125 batches | lr 0.0000 | ms/batch 554.66 | loss  0.45 | cls  0.45 | err  0.15 | 
scGPT - INFO - | epoch   2 | 200/7125 batches | lr 0.0000 | ms/batch 529.06 | loss  0.47 | cls  0.47 | err  0.16 | 
scGPT - INFO - | epoch   2 | 300/7125 batches | lr 0.0000 | ms/batch 527.52 | loss  0.47 | cls  0.47 | err  0.16 | 
scGPT - INFO - | epoch   2 | 400/7125 batches | lr 0.0000 | ms/batch 527.78 | loss  0.47 | cls  0.47 | err  0.15 | 
scGPT - INFO - | epoch   2 | 500/7125 batches | lr 0.0000 | ms/batch 529.34 | loss  0.51 | cls  0.51 | err  0.17 | 
scGPT - INFO - | epoch   2 | 600/7125 batches | lr 0.0000 | ms/batch 529.35 | loss  0.51 | cls  0.51 | err  0.17 | 
scGPT - INFO - | epoch   2 | 700/7125 batches | lr 0.0000 | ms/batch 529.47 | loss  0.46 | cls  0.46 | err  0.16 | 
scGPT - INFO - | epoch   2 | 800/7125 batches | lr 0.0000 | ms/batch 529.20 | loss  0.43 | cls  0.43 | err  0.15 | 
scGPT - INFO - | epoch   2 | 900/7125 batches | lr 0.0000 | ms/batch 528.82 | loss  0.47 | cls  0.47 | err  0.15 | 
scGPT - INFO - | epoch   2 | 1000/7125 batches | lr 0.0000 | ms/batch 527.70 | loss  0.48 | cls  0.48 | err  0.16 | 
scGPT - INFO - | epoch   2 | 1100/7125 batches | lr 0.0000 | ms/batch 527.97 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   2 | 1200/7125 batches | lr 0.0000 | ms/batch 529.39 | loss  0.46 | cls  0.46 | err  0.15 | 
scGPT - INFO - | epoch   2 | 1300/7125 batches | lr 0.0000 | ms/batch 529.73 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   2 | 1400/7125 batches | lr 0.0000 | ms/batch 530.49 | loss  0.49 | cls  0.49 | err  0.16 | 
scGPT - INFO - | epoch   2 | 1500/7125 batches | lr 0.0000 | ms/batch 528.94 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   2 | 1600/7125 batches | lr 0.0000 | ms/batch 530.04 | loss  0.47 | cls  0.47 | err  0.16 | 
scGPT - INFO - | epoch   2 | 1700/7125 batches | lr 0.0000 | ms/batch 531.29 | loss  0.45 | cls  0.45 | err  0.14 | 
scGPT - INFO - | epoch   2 | 1800/7125 batches | lr 0.0000 | ms/batch 531.28 | loss  0.47 | cls  0.47 | err  0.15 | 
scGPT - INFO - | epoch   2 | 1900/7125 batches | lr 0.0000 | ms/batch 530.79 | loss  0.46 | cls  0.46 | err  0.15 | 
scGPT - INFO - | epoch   2 | 2000/7125 batches | lr 0.0000 | ms/batch 529.91 | loss  0.45 | cls  0.45 | err  0.16 | 
scGPT - INFO - | epoch   2 | 2100/7125 batches | lr 0.0000 | ms/batch 531.41 | loss  0.43 | cls  0.43 | err  0.14 | 
scGPT - INFO - | epoch   2 | 2200/7125 batches | lr 0.0000 | ms/batch 530.10 | loss  0.47 | cls  0.47 | err  0.16 | 
scGPT - INFO - | epoch   2 | 2300/7125 batches | lr 0.0000 | ms/batch 530.26 | loss  0.45 | cls  0.45 | err  0.15 | 
scGPT - INFO - | epoch   2 | 2400/7125 batches | lr 0.0000 | ms/batch 531.55 | loss  0.46 | cls  0.46 | err  0.16 | 
scGPT - INFO - | epoch   2 | 2500/7125 batches | lr 0.0000 | ms/batch 529.96 | loss  0.45 | cls  0.45 | err  0.15 | 
scGPT - INFO - | epoch   2 | 2600/7125 batches | lr 0.0000 | ms/batch 530.41 | loss  0.42 | cls  0.42 | err  0.14 | 
scGPT - INFO - | epoch   2 | 2700/7125 batches | lr 0.0000 | ms/batch 529.24 | loss  0.46 | cls  0.46 | err  0.15 | 
scGPT - INFO - | epoch   2 | 2800/7125 batches | lr 0.0000 | ms/batch 529.16 | loss  0.43 | cls  0.43 | err  0.14 | 
scGPT - INFO - | epoch   2 | 2900/7125 batches | lr 0.0000 | ms/batch 529.17 | loss  0.40 | cls  0.40 | err  0.14 | 
scGPT - INFO - | epoch   2 | 3000/7125 batches | lr 0.0000 | ms/batch 530.58 | loss  0.43 | cls  0.43 | err  0.14 | 
scGPT - INFO - | epoch   2 | 3100/7125 batches | lr 0.0000 | ms/batch 531.38 | loss  0.47 | cls  0.47 | err  0.15 | 
scGPT - INFO - | epoch   2 | 3200/7125 batches | lr 0.0000 | ms/batch 528.64 | loss  0.42 | cls  0.42 | err  0.14 | 
scGPT - INFO - | epoch   2 | 3300/7125 batches | lr 0.0000 | ms/batch 527.95 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   2 | 3400/7125 batches | lr 0.0000 | ms/batch 529.00 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   2 | 3500/7125 batches | lr 0.0000 | ms/batch 527.73 | loss  0.45 | cls  0.45 | err  0.15 | 
scGPT - INFO - | epoch   2 | 3600/7125 batches | lr 0.0000 | ms/batch 529.35 | loss  0.42 | cls  0.42 | err  0.15 | 
scGPT - INFO - | epoch   2 | 3700/7125 batches | lr 0.0000 | ms/batch 529.09 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   2 | 3800/7125 batches | lr 0.0000 | ms/batch 528.84 | loss  0.43 | cls  0.43 | err  0.13 | 
scGPT - INFO - | epoch   2 | 3900/7125 batches | lr 0.0000 | ms/batch 528.89 | loss  0.43 | cls  0.43 | err  0.14 | 
scGPT - INFO - | epoch   2 | 4000/7125 batches | lr 0.0000 | ms/batch 527.75 | loss  0.45 | cls  0.45 | err  0.15 | 
scGPT - INFO - | epoch   2 | 4100/7125 batches | lr 0.0000 | ms/batch 529.03 | loss  0.46 | cls  0.46 | err  0.15 | 
scGPT - INFO - | epoch   2 | 4200/7125 batches | lr 0.0000 | ms/batch 527.81 | loss  0.43 | cls  0.43 | err  0.15 | 
scGPT - INFO - | epoch   2 | 4300/7125 batches | lr 0.0000 | ms/batch 527.71 | loss  0.43 | cls  0.43 | err  0.15 | 
scGPT - INFO - | epoch   2 | 4400/7125 batches | lr 0.0000 | ms/batch 528.99 | loss  0.46 | cls  0.46 | err  0.16 | 
scGPT - INFO - | epoch   2 | 4500/7125 batches | lr 0.0000 | ms/batch 527.62 | loss  0.45 | cls  0.45 | err  0.15 | 
scGPT - INFO - | epoch   2 | 4600/7125 batches | lr 0.0000 | ms/batch 529.02 | loss  0.39 | cls  0.39 | err  0.12 | 
scGPT - INFO - | epoch   2 | 4700/7125 batches | lr 0.0000 | ms/batch 528.86 | loss  0.43 | cls  0.43 | err  0.14 | 
scGPT - INFO - | epoch   2 | 4800/7125 batches | lr 0.0000 | ms/batch 528.93 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   2 | 4900/7125 batches | lr 0.0000 | ms/batch 528.73 | loss  0.43 | cls  0.43 | err  0.15 | 
scGPT - INFO - | epoch   2 | 5000/7125 batches | lr 0.0000 | ms/batch 527.50 | loss  0.41 | cls  0.41 | err  0.13 | 
scGPT - INFO - | epoch   2 | 5100/7125 batches | lr 0.0000 | ms/batch 533.76 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   2 | 5200/7125 batches | lr 0.0000 | ms/batch 527.75 | loss  0.42 | cls  0.42 | err  0.13 | 
scGPT - INFO - | epoch   2 | 5300/7125 batches | lr 0.0000 | ms/batch 527.67 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   2 | 5400/7125 batches | lr 0.0000 | ms/batch 529.10 | loss  0.41 | cls  0.41 | err  0.13 | 
scGPT - INFO - | epoch   2 | 5500/7125 batches | lr 0.0000 | ms/batch 527.68 | loss  0.43 | cls  0.43 | err  0.15 | 
scGPT - INFO - | epoch   2 | 5600/7125 batches | lr 0.0000 | ms/batch 529.13 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   2 | 5700/7125 batches | lr 0.0000 | ms/batch 530.23 | loss  0.42 | cls  0.42 | err  0.14 | 
scGPT - INFO - | epoch   2 | 5800/7125 batches | lr 0.0000 | ms/batch 527.81 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   2 | 5900/7125 batches | lr 0.0000 | ms/batch 528.87 | loss  0.42 | cls  0.42 | err  0.13 | 
scGPT - INFO - | epoch   2 | 6000/7125 batches | lr 0.0000 | ms/batch 528.00 | loss  0.39 | cls  0.39 | err  0.12 | 
scGPT - INFO - | epoch   2 | 6100/7125 batches | lr 0.0000 | ms/batch 528.96 | loss  0.41 | cls  0.41 | err  0.13 | 
scGPT - INFO - | epoch   2 | 6200/7125 batches | lr 0.0000 | ms/batch 527.88 | loss  0.41 | cls  0.41 | err  0.13 | 
scGPT - INFO - | epoch   2 | 6300/7125 batches | lr 0.0000 | ms/batch 527.72 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   2 | 6400/7125 batches | lr 0.0000 | ms/batch 529.17 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   2 | 6500/7125 batches | lr 0.0000 | ms/batch 529.30 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   2 | 6600/7125 batches | lr 0.0000 | ms/batch 528.99 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   2 | 6700/7125 batches | lr 0.0000 | ms/batch 528.78 | loss  0.39 | cls  0.39 | err  0.14 | 
scGPT - INFO - | epoch   2 | 6800/7125 batches | lr 0.0000 | ms/batch 527.73 | loss  0.46 | cls  0.46 | err  0.16 | 
scGPT - INFO - | epoch   2 | 6900/7125 batches | lr 0.0000 | ms/batch 528.61 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   2 | 7000/7125 batches | lr 0.0000 | ms/batch 527.91 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   2 | 7100/7125 batches | lr 0.0000 | ms/batch 529.01 | loss  0.42 | cls  0.42 | err  0.15 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 3943.16s | valid loss/mse 0.4235 | err 0.1422
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.4235
random masking at epoch   3, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch   3 | 100/7125 batches | lr 0.0000 | ms/batch 557.63 | loss  0.39 | cls  0.39 | err  0.14 | 
scGPT - INFO - | epoch   3 | 200/7125 batches | lr 0.0000 | ms/batch 528.46 | loss  0.40 | cls  0.40 | err  0.14 | 
scGPT - INFO - | epoch   3 | 300/7125 batches | lr 0.0000 | ms/batch 527.79 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   3 | 400/7125 batches | lr 0.0000 | ms/batch 528.05 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   3 | 500/7125 batches | lr 0.0000 | ms/batch 528.78 | loss  0.43 | cls  0.43 | err  0.15 | 
scGPT - INFO - | epoch   3 | 600/7125 batches | lr 0.0000 | ms/batch 527.79 | loss  0.44 | cls  0.44 | err  0.15 | 
scGPT - INFO - | epoch   3 | 700/7125 batches | lr 0.0000 | ms/batch 527.54 | loss  0.39 | cls  0.39 | err  0.14 | 
scGPT - INFO - | epoch   3 | 800/7125 batches | lr 0.0000 | ms/batch 529.80 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 900/7125 batches | lr 0.0000 | ms/batch 528.72 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   3 | 1000/7125 batches | lr 0.0000 | ms/batch 529.02 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   3 | 1100/7125 batches | lr 0.0000 | ms/batch 528.99 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 1200/7125 batches | lr 0.0000 | ms/batch 527.59 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   3 | 1300/7125 batches | lr 0.0000 | ms/batch 527.64 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   3 | 1400/7125 batches | lr 0.0000 | ms/batch 528.73 | loss  0.44 | cls  0.44 | err  0.16 | 
scGPT - INFO - | epoch   3 | 1500/7125 batches | lr 0.0000 | ms/batch 527.60 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 1600/7125 batches | lr 0.0000 | ms/batch 527.60 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   3 | 1700/7125 batches | lr 0.0000 | ms/batch 528.80 | loss  0.40 | cls  0.40 | err  0.13 | 
scGPT - INFO - | epoch   3 | 1800/7125 batches | lr 0.0000 | ms/batch 528.48 | loss  0.40 | cls  0.40 | err  0.14 | 
scGPT - INFO - | epoch   3 | 1900/7125 batches | lr 0.0000 | ms/batch 528.75 | loss  0.42 | cls  0.42 | err  0.14 | 
scGPT - INFO - | epoch   3 | 2000/7125 batches | lr 0.0000 | ms/batch 528.76 | loss  0.39 | cls  0.39 | err  0.14 | 
scGPT - INFO - | epoch   3 | 2100/7125 batches | lr 0.0000 | ms/batch 528.80 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   3 | 2200/7125 batches | lr 0.0000 | ms/batch 527.44 | loss  0.40 | cls  0.40 | err  0.14 | 
scGPT - INFO - | epoch   3 | 2300/7125 batches | lr 0.0000 | ms/batch 527.49 | loss  0.40 | cls  0.40 | err  0.14 | 
scGPT - INFO - | epoch   3 | 2400/7125 batches | lr 0.0000 | ms/batch 528.85 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   3 | 2500/7125 batches | lr 0.0000 | ms/batch 527.49 | loss  0.40 | cls  0.40 | err  0.13 | 
scGPT - INFO - | epoch   3 | 2600/7125 batches | lr 0.0000 | ms/batch 527.31 | loss  0.38 | cls  0.38 | err  0.12 | 
scGPT - INFO - | epoch   3 | 2700/7125 batches | lr 0.0000 | ms/batch 528.79 | loss  0.39 | cls  0.39 | err  0.14 | 
scGPT - INFO - | epoch   3 | 2800/7125 batches | lr 0.0000 | ms/batch 528.42 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   3 | 2900/7125 batches | lr 0.0000 | ms/batch 529.30 | loss  0.36 | cls  0.36 | err  0.12 | 
scGPT - INFO - | epoch   3 | 3000/7125 batches | lr 0.0000 | ms/batch 530.85 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 3100/7125 batches | lr 0.0000 | ms/batch 530.01 | loss  0.42 | cls  0.42 | err  0.14 | 
scGPT - INFO - | epoch   3 | 3200/7125 batches | lr 0.0000 | ms/batch 529.30 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   3 | 3300/7125 batches | lr 0.0000 | ms/batch 528.09 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 3400/7125 batches | lr 0.0000 | ms/batch 529.00 | loss  0.38 | cls  0.38 | err  0.14 | 
scGPT - INFO - | epoch   3 | 3500/7125 batches | lr 0.0000 | ms/batch 527.84 | loss  0.40 | cls  0.40 | err  0.13 | 
scGPT - INFO - | epoch   3 | 3600/7125 batches | lr 0.0000 | ms/batch 527.57 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   3 | 3700/7125 batches | lr 0.0000 | ms/batch 528.85 | loss  0.40 | cls  0.40 | err  0.14 | 
scGPT - INFO - | epoch   3 | 3800/7125 batches | lr 0.0000 | ms/batch 528.27 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 3900/7125 batches | lr 0.0000 | ms/batch 529.32 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   3 | 4000/7125 batches | lr 0.0000 | ms/batch 531.88 | loss  0.40 | cls  0.40 | err  0.13 | 
scGPT - INFO - | epoch   3 | 4100/7125 batches | lr 0.0000 | ms/batch 527.64 | loss  0.41 | cls  0.41 | err  0.13 | 
scGPT - INFO - | epoch   3 | 4200/7125 batches | lr 0.0000 | ms/batch 527.38 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 4300/7125 batches | lr 0.0000 | ms/batch 527.23 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   3 | 4400/7125 batches | lr 0.0000 | ms/batch 528.76 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   3 | 4500/7125 batches | lr 0.0000 | ms/batch 527.42 | loss  0.41 | cls  0.41 | err  0.13 | 
scGPT - INFO - | epoch   3 | 4600/7125 batches | lr 0.0000 | ms/batch 527.50 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   3 | 4700/7125 batches | lr 0.0000 | ms/batch 528.98 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 4800/7125 batches | lr 0.0000 | ms/batch 671.32 | loss  0.37 | cls  0.37 | err  0.14 | 
scGPT - INFO - | epoch   3 | 4900/7125 batches | lr 0.0000 | ms/batch 526.42 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 5000/7125 batches | lr 0.0000 | ms/batch 526.97 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   3 | 5100/7125 batches | lr 0.0000 | ms/batch 526.03 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   3 | 5200/7125 batches | lr 0.0000 | ms/batch 526.22 | loss  0.38 | cls  0.38 | err  0.12 | 
scGPT - INFO - | epoch   3 | 5300/7125 batches | lr 0.0000 | ms/batch 526.33 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   3 | 5400/7125 batches | lr 0.0000 | ms/batch 527.56 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   3 | 5500/7125 batches | lr 0.0000 | ms/batch 526.39 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   3 | 5600/7125 batches | lr 0.0000 | ms/batch 526.32 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   3 | 5700/7125 batches | lr 0.0000 | ms/batch 527.68 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 5800/7125 batches | lr 0.0000 | ms/batch 527.18 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   3 | 5900/7125 batches | lr 0.0000 | ms/batch 527.86 | loss  0.38 | cls  0.38 | err  0.12 | 
scGPT - INFO - | epoch   3 | 6000/7125 batches | lr 0.0000 | ms/batch 527.56 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   3 | 6100/7125 batches | lr 0.0000 | ms/batch 527.78 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   3 | 6200/7125 batches | lr 0.0000 | ms/batch 526.44 | loss  0.37 | cls  0.37 | err  0.12 | 
scGPT - INFO - | epoch   3 | 6300/7125 batches | lr 0.0000 | ms/batch 526.42 | loss  0.40 | cls  0.40 | err  0.14 | 
scGPT - INFO - | epoch   3 | 6400/7125 batches | lr 0.0000 | ms/batch 527.92 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   3 | 6500/7125 batches | lr 0.0000 | ms/batch 526.60 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   3 | 6600/7125 batches | lr 0.0000 | ms/batch 526.74 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   3 | 6700/7125 batches | lr 0.0000 | ms/batch 527.83 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   3 | 6800/7125 batches | lr 0.0000 | ms/batch 527.54 | loss  0.41 | cls  0.41 | err  0.14 | 
scGPT - INFO - | epoch   3 | 6900/7125 batches | lr 0.0000 | ms/batch 527.90 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   3 | 7000/7125 batches | lr 0.0000 | ms/batch 527.70 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   3 | 7100/7125 batches | lr 0.0000 | ms/batch 527.92 | loss  0.40 | cls  0.40 | err  0.14 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 3949.77s | valid loss/mse 0.3877 | err 0.1324
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.3877
random masking at epoch   4, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch   4 | 100/7125 batches | lr 0.0000 | ms/batch 559.10 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   4 | 200/7125 batches | lr 0.0000 | ms/batch 526.86 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   4 | 300/7125 batches | lr 0.0000 | ms/batch 527.59 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 400/7125 batches | lr 0.0000 | ms/batch 527.86 | loss  0.36 | cls  0.36 | err  0.12 | 
scGPT - INFO - | epoch   4 | 500/7125 batches | lr 0.0000 | ms/batch 529.68 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   4 | 600/7125 batches | lr 0.0000 | ms/batch 527.72 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   4 | 700/7125 batches | lr 0.0000 | ms/batch 529.96 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   4 | 800/7125 batches | lr 0.0000 | ms/batch 527.74 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 900/7125 batches | lr 0.0000 | ms/batch 529.15 | loss  0.38 | cls  0.38 | err  0.14 | 
scGPT - INFO - | epoch   4 | 1000/7125 batches | lr 0.0000 | ms/batch 529.05 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   4 | 1100/7125 batches | lr 0.0000 | ms/batch 528.89 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 1200/7125 batches | lr 0.0000 | ms/batch 527.82 | loss  0.36 | cls  0.36 | err  0.12 | 
scGPT - INFO - | epoch   4 | 1300/7125 batches | lr 0.0000 | ms/batch 527.98 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   4 | 1400/7125 batches | lr 0.0000 | ms/batch 529.04 | loss  0.41 | cls  0.41 | err  0.15 | 
scGPT - INFO - | epoch   4 | 1500/7125 batches | lr 0.0000 | ms/batch 527.85 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 1600/7125 batches | lr 0.0000 | ms/batch 527.74 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   4 | 1700/7125 batches | lr 0.0000 | ms/batch 529.81 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   4 | 1800/7125 batches | lr 0.0000 | ms/batch 527.85 | loss  0.36 | cls  0.36 | err  0.12 | 
scGPT - INFO - | epoch   4 | 1900/7125 batches | lr 0.0000 | ms/batch 528.92 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   4 | 2000/7125 batches | lr 0.0000 | ms/batch 528.96 | loss  0.35 | cls  0.35 | err  0.13 | 
scGPT - INFO - | epoch   4 | 2100/7125 batches | lr 0.0000 | ms/batch 528.35 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   4 | 2200/7125 batches | lr 0.0000 | ms/batch 527.91 | loss  0.39 | cls  0.39 | err  0.14 | 
scGPT - INFO - | epoch   4 | 2300/7125 batches | lr 0.0000 | ms/batch 527.96 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   4 | 2400/7125 batches | lr 0.0000 | ms/batch 528.92 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   4 | 2500/7125 batches | lr 0.0000 | ms/batch 527.45 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   4 | 2600/7125 batches | lr 0.0000 | ms/batch 527.75 | loss  0.36 | cls  0.36 | err  0.12 | 
scGPT - INFO - | epoch   4 | 2700/7125 batches | lr 0.0000 | ms/batch 529.62 | loss  0.36 | cls  0.36 | err  0.12 | 
scGPT - INFO - | epoch   4 | 2800/7125 batches | lr 0.0000 | ms/batch 527.69 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   4 | 2900/7125 batches | lr 0.0000 | ms/batch 529.51 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   4 | 3000/7125 batches | lr 0.0000 | ms/batch 528.93 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 3100/7125 batches | lr 0.0000 | ms/batch 528.81 | loss  0.39 | cls  0.39 | err  0.13 | 
scGPT - INFO - | epoch   4 | 3200/7125 batches | lr 0.0000 | ms/batch 527.45 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   4 | 3300/7125 batches | lr 0.0000 | ms/batch 527.73 | loss  0.35 | cls  0.35 | err  0.13 | 
scGPT - INFO - | epoch   4 | 3400/7125 batches | lr 0.0000 | ms/batch 529.03 | loss  0.35 | cls  0.35 | err  0.13 | 
scGPT - INFO - | epoch   4 | 3500/7125 batches | lr 0.0000 | ms/batch 527.76 | loss  0.37 | cls  0.37 | err  0.12 | 
scGPT - INFO - | epoch   4 | 3600/7125 batches | lr 0.0000 | ms/batch 527.65 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 3700/7125 batches | lr 0.0000 | ms/batch 529.72 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   4 | 3800/7125 batches | lr 0.0000 | ms/batch 527.67 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   4 | 3900/7125 batches | lr 0.0000 | ms/batch 528.87 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   4 | 4000/7125 batches | lr 0.0000 | ms/batch 529.00 | loss  0.38 | cls  0.38 | err  0.12 | 
scGPT - INFO - | epoch   4 | 4100/7125 batches | lr 0.0000 | ms/batch 529.02 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   4 | 4200/7125 batches | lr 0.0000 | ms/batch 527.47 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   4 | 4300/7125 batches | lr 0.0000 | ms/batch 527.52 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   4 | 4400/7125 batches | lr 0.0000 | ms/batch 528.85 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   4 | 4500/7125 batches | lr 0.0000 | ms/batch 527.72 | loss  0.37 | cls  0.37 | err  0.12 | 
scGPT - INFO - | epoch   4 | 4600/7125 batches | lr 0.0000 | ms/batch 527.80 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   4 | 4700/7125 batches | lr 0.0000 | ms/batch 529.72 | loss  0.36 | cls  0.36 | err  0.12 | 
scGPT - INFO - | epoch   4 | 4800/7125 batches | lr 0.0000 | ms/batch 527.69 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 4900/7125 batches | lr 0.0000 | ms/batch 528.91 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 5000/7125 batches | lr 0.0000 | ms/batch 530.03 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   4 | 5100/7125 batches | lr 0.0000 | ms/batch 527.72 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 5200/7125 batches | lr 0.0000 | ms/batch 527.59 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 5300/7125 batches | lr 0.0000 | ms/batch 527.61 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   4 | 5400/7125 batches | lr 0.0000 | ms/batch 528.68 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   4 | 5500/7125 batches | lr 0.0000 | ms/batch 527.65 | loss  0.36 | cls  0.36 | err  0.12 | 
scGPT - INFO - | epoch   4 | 5600/7125 batches | lr 0.0000 | ms/batch 527.62 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   4 | 5700/7125 batches | lr 0.0000 | ms/batch 529.67 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   4 | 5800/7125 batches | lr 0.0000 | ms/batch 528.50 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   4 | 5900/7125 batches | lr 0.0000 | ms/batch 528.71 | loss  0.35 | cls  0.35 | err  0.11 | 
scGPT - INFO - | epoch   4 | 6000/7125 batches | lr 0.0000 | ms/batch 527.99 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   4 | 6100/7125 batches | lr 0.0000 | ms/batch 527.44 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   4 | 6200/7125 batches | lr 0.0000 | ms/batch 527.44 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   4 | 6300/7125 batches | lr 0.0000 | ms/batch 527.34 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   4 | 6400/7125 batches | lr 0.0000 | ms/batch 528.91 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   4 | 6500/7125 batches | lr 0.0000 | ms/batch 527.66 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   4 | 6600/7125 batches | lr 0.0000 | ms/batch 527.41 | loss  0.37 | cls  0.37 | err  0.12 | 
scGPT - INFO - | epoch   4 | 6700/7125 batches | lr 0.0000 | ms/batch 529.74 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   4 | 6800/7125 batches | lr 0.0000 | ms/batch 528.78 | loss  0.38 | cls  0.38 | err  0.13 | 
scGPT - INFO - | epoch   4 | 6900/7125 batches | lr 0.0000 | ms/batch 528.71 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   4 | 7000/7125 batches | lr 0.0000 | ms/batch 528.75 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   4 | 7100/7125 batches | lr 0.0000 | ms/batch 527.71 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 3938.45s | valid loss/mse 0.3833 | err 0.1321
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.3833
random masking at epoch   5, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch   5 | 100/7125 batches | lr 0.0000 | ms/batch 560.63 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 200/7125 batches | lr 0.0000 | ms/batch 528.57 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   5 | 300/7125 batches | lr 0.0000 | ms/batch 528.09 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   5 | 400/7125 batches | lr 0.0000 | ms/batch 528.70 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   5 | 500/7125 batches | lr 0.0000 | ms/batch 528.56 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   5 | 600/7125 batches | lr 0.0000 | ms/batch 527.56 | loss  0.37 | cls  0.37 | err  0.13 | 
scGPT - INFO - | epoch   5 | 700/7125 batches | lr 0.0000 | ms/batch 528.66 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   5 | 800/7125 batches | lr 0.0000 | ms/batch 527.55 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   5 | 900/7125 batches | lr 0.0000 | ms/batch 528.63 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   5 | 1000/7125 batches | lr 0.0000 | ms/batch 528.80 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   5 | 1100/7125 batches | lr 0.0000 | ms/batch 528.66 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   5 | 1200/7125 batches | lr 0.0000 | ms/batch 534.13 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   5 | 1300/7125 batches | lr 0.0000 | ms/batch 527.45 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 1400/7125 batches | lr 0.0000 | ms/batch 528.78 | loss  0.38 | cls  0.38 | err  0.14 | 
scGPT - INFO - | epoch   5 | 1500/7125 batches | lr 0.0000 | ms/batch 543.22 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   5 | 1600/7125 batches | lr 0.0000 | ms/batch 527.72 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   5 | 1700/7125 batches | lr 0.0000 | ms/batch 534.83 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   5 | 1800/7125 batches | lr 0.0000 | ms/batch 529.09 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   5 | 1900/7125 batches | lr 0.0000 | ms/batch 528.19 | loss  0.35 | cls  0.35 | err  0.13 | 
scGPT - INFO - | epoch   5 | 2000/7125 batches | lr 0.0000 | ms/batch 530.73 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   5 | 2100/7125 batches | lr 0.0000 | ms/batch 528.23 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 2200/7125 batches | lr 0.0000 | ms/batch 528.10 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   5 | 2300/7125 batches | lr 0.0000 | ms/batch 527.53 | loss  0.34 | cls  0.34 | err  0.13 | 
scGPT - INFO - | epoch   5 | 2400/7125 batches | lr 0.0000 | ms/batch 530.90 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   5 | 2500/7125 batches | lr 0.0000 | ms/batch 528.39 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   5 | 2600/7125 batches | lr 0.0000 | ms/batch 527.16 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   5 | 2700/7125 batches | lr 0.0000 | ms/batch 528.95 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   5 | 2800/7125 batches | lr 0.0000 | ms/batch 528.89 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   5 | 2900/7125 batches | lr 0.0000 | ms/batch 528.54 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   5 | 3000/7125 batches | lr 0.0000 | ms/batch 528.84 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 3100/7125 batches | lr 0.0000 | ms/batch 527.54 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   5 | 3200/7125 batches | lr 0.0000 | ms/batch 528.73 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   5 | 3300/7125 batches | lr 0.0000 | ms/batch 527.85 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   5 | 3400/7125 batches | lr 0.0000 | ms/batch 529.39 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 3500/7125 batches | lr 0.0000 | ms/batch 530.34 | loss  0.35 | cls  0.35 | err  0.11 | 
scGPT - INFO - | epoch   5 | 3600/7125 batches | lr 0.0000 | ms/batch 529.59 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   5 | 3700/7125 batches | lr 0.0000 | ms/batch 531.03 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   5 | 3800/7125 batches | lr 0.0000 | ms/batch 531.25 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   5 | 3900/7125 batches | lr 0.0000 | ms/batch 546.77 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   5 | 4000/7125 batches | lr 0.0000 | ms/batch 533.63 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   5 | 4100/7125 batches | lr 0.0000 | ms/batch 539.33 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   5 | 4200/7125 batches | lr 0.0000 | ms/batch 526.68 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 4300/7125 batches | lr 0.0000 | ms/batch 533.07 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   5 | 4400/7125 batches | lr 0.0000 | ms/batch 529.40 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   5 | 4500/7125 batches | lr 0.0000 | ms/batch 530.39 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   5 | 4600/7125 batches | lr 0.0000 | ms/batch 529.32 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   5 | 4700/7125 batches | lr 0.0000 | ms/batch 529.48 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   5 | 4800/7125 batches | lr 0.0000 | ms/batch 529.12 | loss  0.32 | cls  0.32 | err  0.12 | 
scGPT - INFO - | epoch   5 | 4900/7125 batches | lr 0.0000 | ms/batch 530.22 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   5 | 5000/7125 batches | lr 0.0000 | ms/batch 529.08 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 5100/7125 batches | lr 0.0000 | ms/batch 527.62 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 5200/7125 batches | lr 0.0000 | ms/batch 527.50 | loss  0.33 | cls  0.33 | err  0.10 | 
scGPT - INFO - | epoch   5 | 5300/7125 batches | lr 0.0000 | ms/batch 528.86 | loss  0.36 | cls  0.36 | err  0.12 | 
scGPT - INFO - | epoch   5 | 5400/7125 batches | lr 0.0000 | ms/batch 527.39 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   5 | 5500/7125 batches | lr 0.0000 | ms/batch 528.37 | loss  0.34 | cls  0.34 | err  0.11 | 
scGPT - INFO - | epoch   5 | 5600/7125 batches | lr 0.0000 | ms/batch 528.78 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 5700/7125 batches | lr 0.0000 | ms/batch 527.54 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 5800/7125 batches | lr 0.0000 | ms/batch 528.83 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   5 | 5900/7125 batches | lr 0.0000 | ms/batch 528.84 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   5 | 6000/7125 batches | lr 0.0000 | ms/batch 528.87 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   5 | 6100/7125 batches | lr 0.0000 | ms/batch 527.38 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   5 | 6200/7125 batches | lr 0.0000 | ms/batch 527.32 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 6300/7125 batches | lr 0.0000 | ms/batch 536.49 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   5 | 6400/7125 batches | lr 0.0000 | ms/batch 529.48 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   5 | 6500/7125 batches | lr 0.0000 | ms/batch 543.59 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   5 | 6600/7125 batches | lr 0.0000 | ms/batch 526.65 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   5 | 6700/7125 batches | lr 0.0000 | ms/batch 535.33 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   5 | 6800/7125 batches | lr 0.0000 | ms/batch 528.87 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   5 | 6900/7125 batches | lr 0.0000 | ms/batch 528.55 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   5 | 7000/7125 batches | lr 0.0000 | ms/batch 529.16 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   5 | 7100/7125 batches | lr 0.0000 | ms/batch 528.17 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 3951.69s | valid loss/mse 0.3846 | err 0.1311
scGPT - INFO - -----------------------------------------------------------------------------------------
random masking at epoch   6, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch   6 | 100/7125 batches | lr 0.0000 | ms/batch 586.88 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   6 | 200/7125 batches | lr 0.0000 | ms/batch 524.70 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 300/7125 batches | lr 0.0000 | ms/batch 538.88 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   6 | 400/7125 batches | lr 0.0000 | ms/batch 528.66 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 500/7125 batches | lr 0.0000 | ms/batch 528.74 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   6 | 600/7125 batches | lr 0.0000 | ms/batch 527.75 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   6 | 700/7125 batches | lr 0.0000 | ms/batch 527.57 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 800/7125 batches | lr 0.0000 | ms/batch 530.20 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 900/7125 batches | lr 0.0000 | ms/batch 529.24 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   6 | 1000/7125 batches | lr 0.0000 | ms/batch 529.71 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   6 | 1100/7125 batches | lr 0.0000 | ms/batch 529.32 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 1200/7125 batches | lr 0.0000 | ms/batch 527.54 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 1300/7125 batches | lr 0.0000 | ms/batch 527.67 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 1400/7125 batches | lr 0.0000 | ms/batch 528.51 | loss  0.36 | cls  0.36 | err  0.13 | 
scGPT - INFO - | epoch   6 | 1500/7125 batches | lr 0.0000 | ms/batch 529.15 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 1600/7125 batches | lr 0.0000 | ms/batch 527.54 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 1700/7125 batches | lr 0.0000 | ms/batch 527.48 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 1800/7125 batches | lr 0.0000 | ms/batch 528.88 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 1900/7125 batches | lr 0.0000 | ms/batch 528.76 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   6 | 2000/7125 batches | lr 0.0000 | ms/batch 529.05 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   6 | 2100/7125 batches | lr 0.0000 | ms/batch 528.74 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   6 | 2200/7125 batches | lr 0.0000 | ms/batch 527.28 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   6 | 2300/7125 batches | lr 0.0000 | ms/batch 527.23 | loss  0.32 | cls  0.32 | err  0.12 | 
scGPT - INFO - | epoch   6 | 2400/7125 batches | lr 0.0000 | ms/batch 528.09 | loss  0.32 | cls  0.32 | err  0.12 | 
scGPT - INFO - | epoch   6 | 2500/7125 batches | lr 0.0000 | ms/batch 529.16 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 2600/7125 batches | lr 0.0000 | ms/batch 527.17 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 2700/7125 batches | lr 0.0000 | ms/batch 550.03 | loss  0.32 | cls  0.32 | err  0.10 | 
scGPT - INFO - | epoch   6 | 2800/7125 batches | lr 0.0000 | ms/batch 528.76 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   6 | 2900/7125 batches | lr 0.0000 | ms/batch 528.61 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   6 | 3000/7125 batches | lr 0.0000 | ms/batch 528.58 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   6 | 3100/7125 batches | lr 0.0000 | ms/batch 528.74 | loss  0.34 | cls  0.34 | err  0.12 | 
scGPT - INFO - | epoch   6 | 3200/7125 batches | lr 0.0000 | ms/batch 527.05 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   6 | 3300/7125 batches | lr 0.0000 | ms/batch 527.24 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 3400/7125 batches | lr 0.0000 | ms/batch 529.45 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   6 | 3500/7125 batches | lr 0.0000 | ms/batch 527.05 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 3600/7125 batches | lr 0.0000 | ms/batch 526.83 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 3700/7125 batches | lr 0.0000 | ms/batch 528.56 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 3800/7125 batches | lr 0.0000 | ms/batch 527.49 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   6 | 3900/7125 batches | lr 0.0000 | ms/batch 528.76 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   6 | 4000/7125 batches | lr 0.0000 | ms/batch 551.83 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 4100/7125 batches | lr 0.0000 | ms/batch 528.49 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   6 | 4200/7125 batches | lr 0.0000 | ms/batch 527.00 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   6 | 4300/7125 batches | lr 0.0000 | ms/batch 526.89 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   6 | 4400/7125 batches | lr 0.0000 | ms/batch 529.47 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   6 | 4500/7125 batches | lr 0.0000 | ms/batch 527.38 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   6 | 4600/7125 batches | lr 0.0000 | ms/batch 527.24 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   6 | 4700/7125 batches | lr 0.0000 | ms/batch 528.97 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   6 | 4800/7125 batches | lr 0.0000 | ms/batch 527.24 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 4900/7125 batches | lr 0.0000 | ms/batch 528.60 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 5000/7125 batches | lr 0.0000 | ms/batch 528.76 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   6 | 5100/7125 batches | lr 0.0000 | ms/batch 529.04 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   6 | 5200/7125 batches | lr 0.0000 | ms/batch 527.59 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   6 | 5300/7125 batches | lr 0.0000 | ms/batch 527.31 | loss  0.33 | cls  0.33 | err  0.11 | 
scGPT - INFO - | epoch   6 | 5400/7125 batches | lr 0.0000 | ms/batch 529.75 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   6 | 5500/7125 batches | lr 0.0000 | ms/batch 527.35 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   6 | 5600/7125 batches | lr 0.0000 | ms/batch 527.43 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   6 | 5700/7125 batches | lr 0.0000 | ms/batch 528.81 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   6 | 5800/7125 batches | lr 0.0000 | ms/batch 527.45 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   6 | 5900/7125 batches | lr 0.0000 | ms/batch 528.61 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   6 | 6000/7125 batches | lr 0.0000 | ms/batch 530.36 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   6 | 6100/7125 batches | lr 0.0000 | ms/batch 527.64 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   6 | 6200/7125 batches | lr 0.0000 | ms/batch 527.26 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   6 | 6300/7125 batches | lr 0.0000 | ms/batch 527.37 | loss  0.32 | cls  0.32 | err  0.12 | 
scGPT - INFO - | epoch   6 | 6400/7125 batches | lr 0.0000 | ms/batch 529.86 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 6500/7125 batches | lr 0.0000 | ms/batch 527.44 | loss  0.29 | cls  0.29 | err  0.11 | 
scGPT - INFO - | epoch   6 | 6600/7125 batches | lr 0.0000 | ms/batch 527.51 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   6 | 6700/7125 batches | lr 0.0000 | ms/batch 528.85 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   6 | 6800/7125 batches | lr 0.0000 | ms/batch 548.13 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   6 | 6900/7125 batches | lr 0.0000 | ms/batch 527.07 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   6 | 7000/7125 batches | lr 0.0000 | ms/batch 530.26 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   6 | 7100/7125 batches | lr 0.0000 | ms/batch 527.27 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 3949.52s | valid loss/mse 0.3845 | err 0.1293
scGPT - INFO - -----------------------------------------------------------------------------------------
random masking at epoch   7, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch   7 | 100/7125 batches | lr 0.0000 | ms/batch 562.42 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   7 | 200/7125 batches | lr 0.0000 | ms/batch 529.09 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   7 | 300/7125 batches | lr 0.0000 | ms/batch 532.55 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   7 | 400/7125 batches | lr 0.0000 | ms/batch 529.50 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 500/7125 batches | lr 0.0000 | ms/batch 529.41 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   7 | 600/7125 batches | lr 0.0000 | ms/batch 529.69 | loss  0.32 | cls  0.32 | err  0.12 | 
scGPT - INFO - | epoch   7 | 700/7125 batches | lr 0.0000 | ms/batch 529.60 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 800/7125 batches | lr 0.0000 | ms/batch 529.44 | loss  0.29 | cls  0.29 | err  0.11 | 
scGPT - INFO - | epoch   7 | 900/7125 batches | lr 0.0000 | ms/batch 529.98 | loss  0.32 | cls  0.32 | err  0.12 | 
scGPT - INFO - | epoch   7 | 1000/7125 batches | lr 0.0000 | ms/batch 529.04 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   7 | 1100/7125 batches | lr 0.0000 | ms/batch 528.64 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 1200/7125 batches | lr 0.0000 | ms/batch 528.46 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 1300/7125 batches | lr 0.0000 | ms/batch 529.45 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   7 | 1400/7125 batches | lr 0.0000 | ms/batch 527.12 | loss  0.35 | cls  0.35 | err  0.12 | 
scGPT - INFO - | epoch   7 | 1500/7125 batches | lr 0.0000 | ms/batch 527.08 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 1600/7125 batches | lr 0.0000 | ms/batch 528.46 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   7 | 1700/7125 batches | lr 0.0000 | ms/batch 527.08 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 1800/7125 batches | lr 0.0000 | ms/batch 527.17 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 1900/7125 batches | lr 0.0000 | ms/batch 528.34 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   7 | 2000/7125 batches | lr 0.0000 | ms/batch 526.91 | loss  0.29 | cls  0.29 | err  0.11 | 
scGPT - INFO - | epoch   7 | 2100/7125 batches | lr 0.0000 | ms/batch 528.29 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   7 | 2200/7125 batches | lr 0.0000 | ms/batch 528.23 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   7 | 2300/7125 batches | lr 0.0000 | ms/batch 529.13 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   7 | 2400/7125 batches | lr 0.0000 | ms/batch 527.04 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   7 | 2500/7125 batches | lr 0.0000 | ms/batch 527.06 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   7 | 2600/7125 batches | lr 0.0000 | ms/batch 528.55 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   7 | 2700/7125 batches | lr 0.0000 | ms/batch 527.10 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   7 | 2800/7125 batches | lr 0.0000 | ms/batch 527.14 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   7 | 2900/7125 batches | lr 0.0000 | ms/batch 528.53 | loss  0.26 | cls  0.26 | err  0.08 | 
scGPT - INFO - | epoch   7 | 3000/7125 batches | lr 0.0000 | ms/batch 527.07 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   7 | 3100/7125 batches | lr 0.0000 | ms/batch 528.41 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   7 | 3200/7125 batches | lr 0.0000 | ms/batch 529.96 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   7 | 3300/7125 batches | lr 0.0000 | ms/batch 527.79 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 3400/7125 batches | lr 0.0000 | ms/batch 527.00 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 3500/7125 batches | lr 0.0000 | ms/batch 527.10 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   7 | 3600/7125 batches | lr 0.0000 | ms/batch 528.25 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 3700/7125 batches | lr 0.0000 | ms/batch 527.06 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   7 | 3800/7125 batches | lr 0.0000 | ms/batch 526.88 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   7 | 3900/7125 batches | lr 0.0000 | ms/batch 528.34 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   7 | 4000/7125 batches | lr 0.0000 | ms/batch 528.31 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   7 | 4100/7125 batches | lr 0.0000 | ms/batch 528.34 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   7 | 4200/7125 batches | lr 0.0000 | ms/batch 528.20 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 4300/7125 batches | lr 0.0000 | ms/batch 527.94 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   7 | 4400/7125 batches | lr 0.0000 | ms/batch 527.13 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   7 | 4500/7125 batches | lr 0.0000 | ms/batch 526.86 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   7 | 4600/7125 batches | lr 0.0000 | ms/batch 528.31 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   7 | 4700/7125 batches | lr 0.0000 | ms/batch 526.99 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 4800/7125 batches | lr 0.0000 | ms/batch 526.97 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   7 | 4900/7125 batches | lr 0.0000 | ms/batch 528.39 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   7 | 5000/7125 batches | lr 0.0000 | ms/batch 528.41 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   7 | 5100/7125 batches | lr 0.0000 | ms/batch 528.36 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 5200/7125 batches | lr 0.0000 | ms/batch 528.20 | loss  0.29 | cls  0.29 | err  0.09 | 
scGPT - INFO - | epoch   7 | 5300/7125 batches | lr 0.0000 | ms/batch 527.87 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   7 | 5400/7125 batches | lr 0.0000 | ms/batch 526.99 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   7 | 5500/7125 batches | lr 0.0000 | ms/batch 527.15 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 5600/7125 batches | lr 0.0000 | ms/batch 528.22 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   7 | 5700/7125 batches | lr 0.0000 | ms/batch 527.12 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   7 | 5800/7125 batches | lr 0.0000 | ms/batch 527.02 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   7 | 5900/7125 batches | lr 0.0000 | ms/batch 528.14 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   7 | 6000/7125 batches | lr 0.0000 | ms/batch 528.11 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   7 | 6100/7125 batches | lr 0.0000 | ms/batch 528.20 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   7 | 6200/7125 batches | lr 0.0000 | ms/batch 528.07 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   7 | 6300/7125 batches | lr 0.0000 | ms/batch 527.58 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   7 | 6400/7125 batches | lr 0.0000 | ms/batch 526.78 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   7 | 6500/7125 batches | lr 0.0000 | ms/batch 526.98 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   7 | 6600/7125 batches | lr 0.0000 | ms/batch 528.06 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   7 | 6700/7125 batches | lr 0.0000 | ms/batch 526.92 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   7 | 6800/7125 batches | lr 0.0000 | ms/batch 527.99 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   7 | 6900/7125 batches | lr 0.0000 | ms/batch 526.87 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   7 | 7000/7125 batches | lr 0.0000 | ms/batch 527.83 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   7 | 7100/7125 batches | lr 0.0000 | ms/batch 527.94 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 3936.56s | valid loss/mse 0.3851 | err 0.1266
scGPT - INFO - -----------------------------------------------------------------------------------------
random masking at epoch   8, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch   8 | 100/7125 batches | lr 0.0000 | ms/batch 560.58 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 200/7125 batches | lr 0.0000 | ms/batch 529.42 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   8 | 300/7125 batches | lr 0.0000 | ms/batch 530.36 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   8 | 400/7125 batches | lr 0.0000 | ms/batch 527.75 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 500/7125 batches | lr 0.0000 | ms/batch 529.57 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 600/7125 batches | lr 0.0000 | ms/batch 530.60 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   8 | 700/7125 batches | lr 0.0000 | ms/batch 527.98 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   8 | 800/7125 batches | lr 0.0000 | ms/batch 527.86 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   8 | 900/7125 batches | lr 0.0000 | ms/batch 527.97 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch   8 | 1000/7125 batches | lr 0.0000 | ms/batch 529.21 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   8 | 1100/7125 batches | lr 0.0000 | ms/batch 527.90 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   8 | 1200/7125 batches | lr 0.0000 | ms/batch 528.72 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 1300/7125 batches | lr 0.0000 | ms/batch 529.09 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 1400/7125 batches | lr 0.0000 | ms/batch 529.09 | loss  0.33 | cls  0.33 | err  0.12 | 
scGPT - INFO - | epoch   8 | 1500/7125 batches | lr 0.0000 | ms/batch 527.90 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   8 | 1600/7125 batches | lr 0.0000 | ms/batch 530.25 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 1700/7125 batches | lr 0.0000 | ms/batch 527.85 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   8 | 1800/7125 batches | lr 0.0000 | ms/batch 527.87 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   8 | 1900/7125 batches | lr 0.0000 | ms/batch 527.79 | loss  0.29 | cls  0.29 | err  0.11 | 
scGPT - INFO - | epoch   8 | 2000/7125 batches | lr 0.0000 | ms/batch 529.08 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   8 | 2100/7125 batches | lr 0.0000 | ms/batch 528.00 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   8 | 2200/7125 batches | lr 0.0000 | ms/batch 528.92 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   8 | 2300/7125 batches | lr 0.0000 | ms/batch 529.00 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 2400/7125 batches | lr 0.0000 | ms/batch 529.05 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   8 | 2500/7125 batches | lr 0.0000 | ms/batch 529.00 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   8 | 2600/7125 batches | lr 0.0000 | ms/batch 528.85 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   8 | 2700/7125 batches | lr 0.0000 | ms/batch 527.73 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   8 | 2800/7125 batches | lr 0.0000 | ms/batch 527.65 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   8 | 2900/7125 batches | lr 0.0000 | ms/batch 527.83 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   8 | 3000/7125 batches | lr 0.0000 | ms/batch 528.91 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 3100/7125 batches | lr 0.0000 | ms/batch 527.64 | loss  0.31 | cls  0.31 | err  0.10 | 
scGPT - INFO - | epoch   8 | 3200/7125 batches | lr 0.0000 | ms/batch 528.66 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   8 | 3300/7125 batches | lr 0.0000 | ms/batch 528.89 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   8 | 3400/7125 batches | lr 0.0000 | ms/batch 528.97 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 3500/7125 batches | lr 0.0000 | ms/batch 528.94 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 3600/7125 batches | lr 0.0000 | ms/batch 528.88 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 3700/7125 batches | lr 0.0000 | ms/batch 527.66 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 3800/7125 batches | lr 0.0000 | ms/batch 527.72 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 3900/7125 batches | lr 0.0000 | ms/batch 527.73 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   8 | 4000/7125 batches | lr 0.0000 | ms/batch 529.20 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   8 | 4100/7125 batches | lr 0.0000 | ms/batch 527.85 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 4200/7125 batches | lr 0.0000 | ms/batch 528.63 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 4300/7125 batches | lr 0.0000 | ms/batch 528.72 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   8 | 4400/7125 batches | lr 0.0000 | ms/batch 529.06 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 4500/7125 batches | lr 0.0000 | ms/batch 528.94 | loss  0.30 | cls  0.30 | err  0.11 | 
scGPT - INFO - | epoch   8 | 4600/7125 batches | lr 0.0000 | ms/batch 529.12 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch   8 | 4700/7125 batches | lr 0.0000 | ms/batch 527.81 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 4800/7125 batches | lr 0.0000 | ms/batch 527.85 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 4900/7125 batches | lr 0.0000 | ms/batch 529.06 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 5000/7125 batches | lr 0.0000 | ms/batch 527.70 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   8 | 5100/7125 batches | lr 0.0000 | ms/batch 527.62 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   8 | 5200/7125 batches | lr 0.0000 | ms/batch 529.79 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   8 | 5300/7125 batches | lr 0.0000 | ms/batch 527.72 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 5400/7125 batches | lr 0.0000 | ms/batch 528.81 | loss  0.25 | cls  0.25 | err  0.08 | 
scGPT - INFO - | epoch   8 | 5500/7125 batches | lr 0.0000 | ms/batch 528.80 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   8 | 5600/7125 batches | lr 0.0000 | ms/batch 528.85 | loss  0.26 | cls  0.26 | err  0.10 | 
scGPT - INFO - | epoch   8 | 5700/7125 batches | lr 0.0000 | ms/batch 527.63 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   8 | 5800/7125 batches | lr 0.0000 | ms/batch 527.62 | loss  0.24 | cls  0.24 | err  0.09 | 
scGPT - INFO - | epoch   8 | 5900/7125 batches | lr 0.0000 | ms/batch 528.95 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   8 | 6000/7125 batches | lr 0.0000 | ms/batch 527.46 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   8 | 6100/7125 batches | lr 0.0000 | ms/batch 527.73 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   8 | 6200/7125 batches | lr 0.0000 | ms/batch 529.69 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 6300/7125 batches | lr 0.0000 | ms/batch 527.49 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 6400/7125 batches | lr 0.0000 | ms/batch 528.91 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   8 | 6500/7125 batches | lr 0.0000 | ms/batch 529.17 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   8 | 6600/7125 batches | lr 0.0000 | ms/batch 529.02 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   8 | 6700/7125 batches | lr 0.0000 | ms/batch 527.80 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   8 | 6800/7125 batches | lr 0.0000 | ms/batch 527.60 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   8 | 6900/7125 batches | lr 0.0000 | ms/batch 528.99 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   8 | 7000/7125 batches | lr 0.0000 | ms/batch 527.73 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   8 | 7100/7125 batches | lr 0.0000 | ms/batch 527.83 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 3940.28s | valid loss/mse 0.3888 | err 0.1214
scGPT - INFO - -----------------------------------------------------------------------------------------
random masking at epoch   9, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch   9 | 100/7125 batches | lr 0.0000 | ms/batch 564.62 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   9 | 200/7125 batches | lr 0.0000 | ms/batch 529.03 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   9 | 300/7125 batches | lr 0.0000 | ms/batch 528.11 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   9 | 400/7125 batches | lr 0.0000 | ms/batch 528.51 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 500/7125 batches | lr 0.0000 | ms/batch 529.08 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   9 | 600/7125 batches | lr 0.0000 | ms/batch 527.91 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   9 | 700/7125 batches | lr 0.0000 | ms/batch 527.87 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 800/7125 batches | lr 0.0000 | ms/batch 529.02 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   9 | 900/7125 batches | lr 0.0000 | ms/batch 527.88 | loss  0.30 | cls  0.30 | err  0.10 | 
scGPT - INFO - | epoch   9 | 1000/7125 batches | lr 0.0000 | ms/batch 529.85 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   9 | 1100/7125 batches | lr 0.0000 | ms/batch 530.17 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 1200/7125 batches | lr 0.0000 | ms/batch 527.65 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   9 | 1300/7125 batches | lr 0.0000 | ms/batch 527.68 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 1400/7125 batches | lr 0.0000 | ms/batch 527.50 | loss  0.32 | cls  0.32 | err  0.11 | 
scGPT - INFO - | epoch   9 | 1500/7125 batches | lr 0.0000 | ms/batch 528.80 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   9 | 1600/7125 batches | lr 0.0000 | ms/batch 527.62 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   9 | 1700/7125 batches | lr 0.0000 | ms/batch 527.48 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 1800/7125 batches | lr 0.0000 | ms/batch 529.00 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 1900/7125 batches | lr 0.0000 | ms/batch 528.74 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   9 | 2000/7125 batches | lr 0.0000 | ms/batch 529.43 | loss  0.26 | cls  0.26 | err  0.10 | 
scGPT - INFO - | epoch   9 | 2100/7125 batches | lr 0.0000 | ms/batch 528.73 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch   9 | 2200/7125 batches | lr 0.0000 | ms/batch 527.56 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   9 | 2300/7125 batches | lr 0.0000 | ms/batch 527.64 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   9 | 2400/7125 batches | lr 0.0000 | ms/batch 527.64 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   9 | 2500/7125 batches | lr 0.0000 | ms/batch 528.58 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   9 | 2600/7125 batches | lr 0.0000 | ms/batch 527.47 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   9 | 2700/7125 batches | lr 0.0000 | ms/batch 527.63 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 2800/7125 batches | lr 0.0000 | ms/batch 528.97 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   9 | 2900/7125 batches | lr 0.0000 | ms/batch 528.80 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch   9 | 3000/7125 batches | lr 0.0000 | ms/batch 529.88 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 3100/7125 batches | lr 0.0000 | ms/batch 528.76 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   9 | 3200/7125 batches | lr 0.0000 | ms/batch 527.61 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch   9 | 3300/7125 batches | lr 0.0000 | ms/batch 527.83 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 3400/7125 batches | lr 0.0000 | ms/batch 527.71 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 3500/7125 batches | lr 0.0000 | ms/batch 528.95 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch   9 | 3600/7125 batches | lr 0.0000 | ms/batch 527.52 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 3700/7125 batches | lr 0.0000 | ms/batch 528.01 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   9 | 3800/7125 batches | lr 0.0000 | ms/batch 528.79 | loss  0.24 | cls  0.24 | err  0.09 | 
scGPT - INFO - | epoch   9 | 3900/7125 batches | lr 0.0000 | ms/batch 528.70 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   9 | 4000/7125 batches | lr 0.0000 | ms/batch 529.99 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 4100/7125 batches | lr 0.0000 | ms/batch 528.93 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   9 | 4200/7125 batches | lr 0.0000 | ms/batch 527.69 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   9 | 4300/7125 batches | lr 0.0000 | ms/batch 527.52 | loss  0.29 | cls  0.29 | err  0.09 | 
scGPT - INFO - | epoch   9 | 4400/7125 batches | lr 0.0000 | ms/batch 527.51 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   9 | 4500/7125 batches | lr 0.0000 | ms/batch 528.95 | loss  0.29 | cls  0.29 | err  0.10 | 
scGPT - INFO - | epoch   9 | 4600/7125 batches | lr 0.0000 | ms/batch 527.86 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch   9 | 4700/7125 batches | lr 0.0000 | ms/batch 527.65 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 4800/7125 batches | lr 0.0000 | ms/batch 528.76 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   9 | 4900/7125 batches | lr 0.0000 | ms/batch 529.01 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   9 | 5000/7125 batches | lr 0.0000 | ms/batch 529.89 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   9 | 5100/7125 batches | lr 0.0000 | ms/batch 528.83 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   9 | 5200/7125 batches | lr 0.0000 | ms/batch 527.55 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 5300/7125 batches | lr 0.0000 | ms/batch 527.77 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch   9 | 5400/7125 batches | lr 0.0000 | ms/batch 528.84 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch   9 | 5500/7125 batches | lr 0.0000 | ms/batch 527.49 | loss  0.26 | cls  0.26 | err  0.08 | 
scGPT - INFO - | epoch   9 | 5600/7125 batches | lr 0.0000 | ms/batch 527.76 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch   9 | 5700/7125 batches | lr 0.0000 | ms/batch 528.87 | loss  0.25 | cls  0.25 | err  0.08 | 
scGPT - INFO - | epoch   9 | 5800/7125 batches | lr 0.0000 | ms/batch 527.67 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch   9 | 5900/7125 batches | lr 0.0000 | ms/batch 528.89 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch   9 | 6000/7125 batches | lr 0.0000 | ms/batch 529.76 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch   9 | 6100/7125 batches | lr 0.0000 | ms/batch 528.77 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch   9 | 6200/7125 batches | lr 0.0000 | ms/batch 527.61 | loss  0.25 | cls  0.25 | err  0.08 | 
scGPT - INFO - | epoch   9 | 6300/7125 batches | lr 0.0000 | ms/batch 527.52 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   9 | 6400/7125 batches | lr 0.0000 | ms/batch 528.98 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   9 | 6500/7125 batches | lr 0.0000 | ms/batch 527.66 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch   9 | 6600/7125 batches | lr 0.0000 | ms/batch 527.55 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch   9 | 6700/7125 batches | lr 0.0000 | ms/batch 528.84 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch   9 | 6800/7125 batches | lr 0.0000 | ms/batch 527.53 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch   9 | 6900/7125 batches | lr 0.0000 | ms/batch 528.90 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch   9 | 7000/7125 batches | lr 0.0000 | ms/batch 529.77 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch   9 | 7100/7125 batches | lr 0.0000 | ms/batch 528.72 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 3939.75s | valid loss/mse 0.3963 | err 0.1229
scGPT - INFO - -----------------------------------------------------------------------------------------
random masking at epoch  10, ratio of masked values in train:  0.0000
scGPT - INFO - | epoch  10 | 100/7125 batches | lr 0.0000 | ms/batch 563.62 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 200/7125 batches | lr 0.0000 | ms/batch 527.44 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch  10 | 300/7125 batches | lr 0.0000 | ms/batch 527.85 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 400/7125 batches | lr 0.0000 | ms/batch 527.06 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch  10 | 500/7125 batches | lr 0.0000 | ms/batch 527.79 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch  10 | 600/7125 batches | lr 0.0000 | ms/batch 527.30 | loss  0.27 | cls  0.27 | err  0.10 | 
scGPT - INFO - | epoch  10 | 700/7125 batches | lr 0.0000 | ms/batch 528.74 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch  10 | 800/7125 batches | lr 0.0000 | ms/batch 527.52 | loss  0.24 | cls  0.24 | err  0.09 | 
scGPT - INFO - | epoch  10 | 900/7125 batches | lr 0.0000 | ms/batch 528.44 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch  10 | 1000/7125 batches | lr 0.0000 | ms/batch 528.82 | loss  0.28 | cls  0.28 | err  0.10 | 
scGPT - INFO - | epoch  10 | 1100/7125 batches | lr 0.0000 | ms/batch 528.75 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch  10 | 1200/7125 batches | lr 0.0000 | ms/batch 528.77 | loss  0.25 | cls  0.25 | err  0.08 | 
scGPT - INFO - | epoch  10 | 1300/7125 batches | lr 0.0000 | ms/batch 528.72 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch  10 | 1400/7125 batches | lr 0.0000 | ms/batch 527.49 | loss  0.31 | cls  0.31 | err  0.11 | 
scGPT - INFO - | epoch  10 | 1500/7125 batches | lr 0.0000 | ms/batch 527.56 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 1600/7125 batches | lr 0.0000 | ms/batch 527.63 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 1700/7125 batches | lr 0.0000 | ms/batch 528.81 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 1800/7125 batches | lr 0.0000 | ms/batch 527.52 | loss  0.25 | cls  0.25 | err  0.08 | 
scGPT - INFO - | epoch  10 | 1900/7125 batches | lr 0.0000 | ms/batch 528.44 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 2000/7125 batches | lr 0.0000 | ms/batch 528.64 | loss  0.24 | cls  0.24 | err  0.09 | 
scGPT - INFO - | epoch  10 | 2100/7125 batches | lr 0.0000 | ms/batch 528.76 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch  10 | 2200/7125 batches | lr 0.0000 | ms/batch 528.88 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch  10 | 2300/7125 batches | lr 0.0000 | ms/batch 528.69 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch  10 | 2400/7125 batches | lr 0.0000 | ms/batch 527.58 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 2500/7125 batches | lr 0.0000 | ms/batch 527.49 | loss  0.26 | cls  0.26 | err  0.08 | 
scGPT - INFO - | epoch  10 | 2600/7125 batches | lr 0.0000 | ms/batch 528.92 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch  10 | 2700/7125 batches | lr 0.0000 | ms/batch 527.38 | loss  0.25 | cls  0.25 | err  0.08 | 
scGPT - INFO - | epoch  10 | 2800/7125 batches | lr 0.0000 | ms/batch 527.60 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch  10 | 2900/7125 batches | lr 0.0000 | ms/batch 529.64 | loss  0.22 | cls  0.22 | err  0.08 | 
scGPT - INFO - | epoch  10 | 3000/7125 batches | lr 0.0000 | ms/batch 527.56 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 3100/7125 batches | lr 0.0000 | ms/batch 528.68 | loss  0.28 | cls  0.28 | err  0.09 | 
scGPT - INFO - | epoch  10 | 3200/7125 batches | lr 0.0000 | ms/batch 528.67 | loss  0.22 | cls  0.22 | err  0.07 | 
scGPT - INFO - | epoch  10 | 3300/7125 batches | lr 0.0000 | ms/batch 528.64 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch  10 | 3400/7125 batches | lr 0.0000 | ms/batch 527.51 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 3500/7125 batches | lr 0.0000 | ms/batch 527.47 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 3600/7125 batches | lr 0.0000 | ms/batch 528.64 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 3700/7125 batches | lr 0.0000 | ms/batch 527.38 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 3800/7125 batches | lr 0.0000 | ms/batch 527.48 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 3900/7125 batches | lr 0.0000 | ms/batch 529.46 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 4000/7125 batches | lr 0.0000 | ms/batch 527.44 | loss  0.25 | cls  0.25 | err  0.08 | 
scGPT - INFO - | epoch  10 | 4100/7125 batches | lr 0.0000 | ms/batch 528.72 | loss  0.26 | cls  0.26 | err  0.08 | 
scGPT - INFO - | epoch  10 | 4200/7125 batches | lr 0.0000 | ms/batch 528.67 | loss  0.24 | cls  0.24 | err  0.09 | 
scGPT - INFO - | epoch  10 | 4300/7125 batches | lr 0.0000 | ms/batch 527.91 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch  10 | 4400/7125 batches | lr 0.0000 | ms/batch 527.48 | loss  0.26 | cls  0.26 | err  0.10 | 
scGPT - INFO - | epoch  10 | 4500/7125 batches | lr 0.0000 | ms/batch 527.39 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch  10 | 4600/7125 batches | lr 0.0000 | ms/batch 528.71 | loss  0.22 | cls  0.22 | err  0.07 | 
scGPT - INFO - | epoch  10 | 4700/7125 batches | lr 0.0000 | ms/batch 527.43 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 4800/7125 batches | lr 0.0000 | ms/batch 527.35 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch  10 | 4900/7125 batches | lr 0.0000 | ms/batch 529.56 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 5000/7125 batches | lr 0.0000 | ms/batch 527.50 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch  10 | 5100/7125 batches | lr 0.0000 | ms/batch 528.47 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 5200/7125 batches | lr 0.0000 | ms/batch 528.44 | loss  0.25 | cls  0.25 | err  0.08 | 
scGPT - INFO - | epoch  10 | 5300/7125 batches | lr 0.0000 | ms/batch 528.42 | loss  0.27 | cls  0.27 | err  0.09 | 
scGPT - INFO - | epoch  10 | 5400/7125 batches | lr 0.0000 | ms/batch 527.17 | loss  0.22 | cls  0.22 | err  0.08 | 
scGPT - INFO - | epoch  10 | 5500/7125 batches | lr 0.0000 | ms/batch 527.50 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 5600/7125 batches | lr 0.0000 | ms/batch 528.70 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - | epoch  10 | 5700/7125 batches | lr 0.0000 | ms/batch 527.34 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch  10 | 5800/7125 batches | lr 0.0000 | ms/batch 527.58 | loss  0.22 | cls  0.22 | err  0.08 | 
scGPT - INFO - | epoch  10 | 5900/7125 batches | lr 0.0000 | ms/batch 529.59 | loss  0.22 | cls  0.22 | err  0.07 | 
scGPT - INFO - | epoch  10 | 6000/7125 batches | lr 0.0000 | ms/batch 527.41 | loss  0.21 | cls  0.21 | err  0.07 | 
scGPT - INFO - | epoch  10 | 6100/7125 batches | lr 0.0000 | ms/batch 528.69 | loss  0.22 | cls  0.22 | err  0.08 | 
scGPT - INFO - | epoch  10 | 6200/7125 batches | lr 0.0000 | ms/batch 528.65 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch  10 | 6300/7125 batches | lr 0.0000 | ms/batch 528.56 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 6400/7125 batches | lr 0.0000 | ms/batch 527.56 | loss  0.24 | cls  0.24 | err  0.08 | 
scGPT - INFO - | epoch  10 | 6500/7125 batches | lr 0.0000 | ms/batch 527.69 | loss  0.23 | cls  0.23 | err  0.09 | 
scGPT - INFO - | epoch  10 | 6600/7125 batches | lr 0.0000 | ms/batch 528.78 | loss  0.26 | cls  0.26 | err  0.09 | 
scGPT - INFO - | epoch  10 | 6700/7125 batches | lr 0.0000 | ms/batch 527.55 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch  10 | 6800/7125 batches | lr 0.0000 | ms/batch 527.47 | loss  0.25 | cls  0.25 | err  0.08 | 
scGPT - INFO - | epoch  10 | 6900/7125 batches | lr 0.0000 | ms/batch 529.39 | loss  0.23 | cls  0.23 | err  0.08 | 
scGPT - INFO - | epoch  10 | 7000/7125 batches | lr 0.0000 | ms/batch 527.49 | loss  0.22 | cls  0.22 | err  0.07 | 
scGPT - INFO - | epoch  10 | 7100/7125 batches | lr 0.0000 | ms/batch 528.57 | loss  0.25 | cls  0.25 | err  0.09 | 
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 3938.19s | valid loss/mse 0.4128 | err 0.1228
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Accuracy: 0.864, Precision: 0.775, Recall: 0.702, Macro F1: 0.722
[1;34mwandb[0m: üöÄ View run [33msage-eon-119[0m at: [34mhttps://wandb.ai/srks-uc-san-diego/scGPT-covid-annotation/runs/zy7pstmg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250306_200750-zy7pstmg/logs[0m
